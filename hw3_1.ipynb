{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "dataset = pd.read_csv('./train.csv') #用來當training資料的\n",
    "X_test = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open Price</th>\n",
       "      <th>Close Price</th>\n",
       "      <th>High Price</th>\n",
       "      <th>Low Price</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2259</th>\n",
       "      <td>22-Dec-2017</td>\n",
       "      <td>2684.22</td>\n",
       "      <td>2683.34</td>\n",
       "      <td>2685.35</td>\n",
       "      <td>2678.13</td>\n",
       "      <td>1383888512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2260</th>\n",
       "      <td>26-Dec-2017</td>\n",
       "      <td>2679.09</td>\n",
       "      <td>2680.50</td>\n",
       "      <td>2682.74</td>\n",
       "      <td>2677.96</td>\n",
       "      <td>1103808384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2261</th>\n",
       "      <td>27-Dec-2017</td>\n",
       "      <td>2682.10</td>\n",
       "      <td>2682.62</td>\n",
       "      <td>2685.64</td>\n",
       "      <td>2678.91</td>\n",
       "      <td>1149108352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2262</th>\n",
       "      <td>28-Dec-2017</td>\n",
       "      <td>2686.10</td>\n",
       "      <td>2687.54</td>\n",
       "      <td>2687.66</td>\n",
       "      <td>2682.69</td>\n",
       "      <td>1126089856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2263</th>\n",
       "      <td>29-Dec-2017</td>\n",
       "      <td>2689.15</td>\n",
       "      <td>2673.61</td>\n",
       "      <td>2692.12</td>\n",
       "      <td>2673.61</td>\n",
       "      <td>1332374016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date  Open Price  Close Price  High Price  Low Price      Volume\n",
       "2259  22-Dec-2017     2684.22      2683.34     2685.35    2678.13  1383888512\n",
       "2260  26-Dec-2017     2679.09      2680.50     2682.74    2677.96  1103808384\n",
       "2261  27-Dec-2017     2682.10      2682.62     2685.64    2678.91  1149108352\n",
       "2262  28-Dec-2017     2686.10      2687.54     2687.66    2682.69  1126089856\n",
       "2263  29-Dec-2017     2689.15      2673.61     2692.12    2673.61  1332374016"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train 資料處理\n",
    "#### 增加movement表示漲跌\n",
    "#### 由於資料太少，增加high price, low price差為一個特徵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuen/.local/lib/python3.5/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/yuen/.local/lib/python3.5/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "dataset['sub'] = 0.0\n",
    "for i in range(0, len(dataset.index)):\n",
    "    dataset['sub'][i] = dataset['High Price'][i] - dataset['Low Price'][i]\n",
    "\n",
    "dataset['movement'] = 0\n",
    "for i in range(1, len(dataset.index)):\n",
    "    if(dataset['Close Price'][i] > dataset['Close Price'][i-1]):\n",
    "        dataset['movement'][i] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由於要預測「明天」是否漲跌，所以將資料向上平移一格。\n",
    "並且因為最後一天的資料沒有「明天」的漲跌，顧刪除。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuen/.local/lib/python3.5/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Date  Open Price  Close Price  High Price  Low Price      Volume  \\\n",
      "2258  21-Dec-2017     2683.02      2684.57     2692.64    2682.40  1933795072   \n",
      "2259  22-Dec-2017     2684.22      2683.34     2685.35    2678.13  1383888512   \n",
      "2260  26-Dec-2017     2679.09      2680.50     2682.74    2677.96  1103808384   \n",
      "2261  27-Dec-2017     2682.10      2682.62     2685.64    2678.91  1149108352   \n",
      "2262  28-Dec-2017     2686.10      2687.54     2687.66    2682.69  1126089856   \n",
      "\n",
      "        sub  movement  \n",
      "2258  10.24         0  \n",
      "2259   7.22         0  \n",
      "2260   4.78         1  \n",
      "2261   6.73         1  \n",
      "2262   4.97         0  \n"
     ]
    }
   ],
   "source": [
    "# 平移\n",
    "for i in range(1, len(dataset.index)):\n",
    "    dataset['movement'][i-1] = dataset['movement'][i]\n",
    "    \n",
    "# 刪除最後一天\n",
    "dataset.drop([len(dataset)-1],inplace=True)\n",
    "print(dataset.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定義train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = dataset.iloc[:, 1:7].values # x捨棄date , .value的話會捨棄掉Close Price那些\n",
    "\n",
    "Y_train = dataset.iloc[:, 7].values # y是movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.02990000e+02 9.31800000e+02 9.34730000e+02 8.99350000e+02\n",
      " 4.04827008e+09 3.53800000e+01]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])\n",
    "print(Y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test data 處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuen/.local/lib/python3.5/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/yuen/.local/lib/python3.5/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/home/yuen/.local/lib/python3.5/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date  Open Price  Close Price  High Price  Low Price      Volume  \\\n",
      "246  21-Dec-2018     2465.38      2416.62     2504.41    2408.55  4560164352   \n",
      "247  24-Dec-2018     2400.56      2351.10     2410.34    2351.10  1662758784   \n",
      "248  26-Dec-2018     2363.12      2467.70     2467.76    2346.58  2611875072   \n",
      "249  27-Dec-2018     2442.50      2488.83     2489.10    2397.94  2386466304   \n",
      "250  28-Dec-2018     2498.77      2485.74     2520.27    2472.89  2080726656   \n",
      "\n",
      "        sub  movement  \n",
      "246   95.86         0  \n",
      "247   59.24         1  \n",
      "248  121.18         1  \n",
      "249   91.16         0  \n",
      "250   47.38         1  \n"
     ]
    }
   ],
   "source": [
    "X_test['sub'] = 0.0\n",
    "for i in range(0, len(X_test.index)):\n",
    "    X_test['sub'][i] = X_test['High Price'][i] - X_test['Low Price'][i]\n",
    "\n",
    "# 計算漲跌\n",
    "X_test['movement'] = 0\n",
    "for i in range(1, len(X_test.index)):\n",
    "    if(X_test['Close Price'][i] > X_test['Close Price'][i-1]):\n",
    "        X_test['movement'][i] = 1\n",
    "        \n",
    "# 平移\n",
    "for i in range(1, len(X_test.index)):\n",
    "    X_test['movement'][i-1] = X_test['movement'][i]\n",
    "    \n",
    "# 刪除最後一天\n",
    "X_test.drop([len(X_test)-1],inplace=True)\n",
    "print(X_test.tail(5))\n",
    "\n",
    "# 定義test資料\n",
    "x_test = X_test.iloc[:, 1:7].values # x捨棄date , .value的話會捨棄掉Close Price那些\n",
    "y_test = X_test.iloc[:, 7].values # y是movement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.45918721 0.54081279]\n",
      " [0.45957526 0.54042474]\n",
      " [0.459584   0.540416  ]\n",
      " [0.45933946 0.54066054]\n",
      " [0.45929252 0.54070748]\n",
      " [0.45940711 0.54059289]\n",
      " [0.45953345 0.54046655]\n",
      " [0.45944088 0.54055912]\n",
      " [0.45959022 0.54040978]\n",
      " [0.45949606 0.54050394]\n",
      " [0.45963108 0.54036892]\n",
      " [0.45964326 0.54035674]\n",
      " [0.45962385 0.54037615]\n",
      " [0.4595731  0.5404269 ]\n",
      " [0.45961854 0.54038146]\n",
      " [0.45961522 0.54038478]\n",
      " [0.45964967 0.54035033]\n",
      " [0.45962356 0.54037644]\n",
      " [0.45957149 0.54042851]\n",
      " [0.45963837 0.54036163]]\n",
      "0.5219123505976095\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, preprocessing\n",
    "\n",
    "# sigmoid\n",
    "svm_model_s = svm.SVC(C = 0.05, kernel='sigmoid', probability=True)\n",
    "svm_model_s.fit(X_train, Y_train)\n",
    "probability = svm_model_s.predict_proba(x_test)\n",
    "print(probability[:20])\n",
    "print(svm_model_s.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(6, 50) \n",
    "        self.fc2 = nn.Linear(50, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.dropout(x, p=0.1)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50 #一組50（一次訓練訓練個2262/50次）\n",
    "num_epochs = 50 #訓練50次\n",
    "learning_rate = 0.01\n",
    "batch_no = len(X_train) # 801"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuen/.local/lib/python3.5/site-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n",
      "Epoch 11\n",
      "Epoch 16\n",
      "Epoch 21\n",
      "Epoch 26\n",
      "Epoch 31\n",
      "Epoch 36\n",
      "Epoch 41\n",
      "Epoch 46\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from torch.autograd import Variable\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    if epoch % 5 == 0:\n",
    "        print('Epoch {}'.format(epoch+1))\n",
    "    X_train, Y_train = shuffle(X_train, Y_train) # 每次都shuffle一次\n",
    "    # 每個 batch learning\n",
    "    for i in range(batch_no // batch_size):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        #丟給model必須是Variable  才能backward\n",
    "        x_var = Variable(torch.FloatTensor(X_train[start:end]))#float\n",
    "        y_var = Variable(torch.LongTensor(Y_train[start:end]))#int\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        ypred_var = net(x_var) \n",
    "        loss =criterion(ypred_var, y_var)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.52\n"
     ]
    }
   ],
   "source": [
    "test_var = Variable(torch.FloatTensor(x_test), requires_grad=True)\n",
    "#test_y = Variable(torch.LongTensor(y_val), requires_grad=True)\n",
    "with torch.no_grad(): #深度學習模型在訓練時會自動計算梯度，若於分析模型在目標函數的表現時不想花多餘資源計算梯度可以使用 with to.no_grad():\n",
    "    result = net(test_var)\n",
    "    \n",
    "values, labels = torch.max(result, 1) # 0以行取max / 0以列取max\n",
    "#MAX會回傳誰比較大 跟該index\n",
    "\n",
    "num_right = np.sum(labels.data.numpy() == y_test)\n",
    "#ACC = 猜中幾個\n",
    "print('Accuracy {:.2f}'.format(num_right / len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as func\n",
    "\n",
    "class logit_model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(logit_model, self).__init__()\n",
    "        self.linear = torch.nn.Linear(6, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return(self.linear(x))\n",
    "\n",
    "\n",
    "net = logit_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Epoch 6\n",
      "Epoch 11\n",
      "Epoch 16\n",
      "Epoch 21\n",
      "Epoch 26\n",
      "Epoch 31\n",
      "Epoch 36\n",
      "Epoch 41\n",
      "Epoch 46\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    if epoch % 5 == 0:\n",
    "        print('Epoch {}'.format(epoch+1))\n",
    "    X_train, Y_train = shuffle(X_train, Y_train) # 每次都shuffle一次\n",
    "    # 每個 batch learning\n",
    "    for i in range(batch_no // batch_size):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        #丟給model必須是Variable  才能backward\n",
    "        x_var = Variable(torch.FloatTensor(X_train[start:end]))#float\n",
    "        y_var = Variable(torch.LongTensor(Y_train[start:end]))#int\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        ypred_var = net(x_var) \n",
    "        loss =criterion(ypred_var, y_var)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.47808765\n"
     ]
    }
   ],
   "source": [
    "test_var = Variable(torch.FloatTensor(x_test), requires_grad=True)\n",
    "#test_y = Variable(torch.LongTensor(y_val), requires_grad=True)\n",
    "with torch.no_grad(): #深度學習模型在訓練時會自動計算梯度，若於分析模型在目標函數的表現時不想花多餘資源計算梯度可以使用 with to.no_grad():\n",
    "    result = net(test_var)\n",
    "\n",
    "values, labels = torch.max(result, 1) # 0以行取max / 0以列取max\n",
    "\n",
    "#MAX會回傳誰比較大 跟該index\n",
    "num_right = np.sum(labels.data.numpy() == y_test)\n",
    "#ACC = 猜中幾個\n",
    "print('Accuracy {:.8f}'.format(num_right / len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## improve - 試試crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = dataset.iloc[:, 1:7].values # x捨棄date , .value的話會捨棄掉Close Price那些\n",
    "\n",
    "Y_train = dataset.iloc[:, 7].values # y是movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(6, 50) \n",
    "        self.fc2 = nn.Linear(50, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.dropout(x, p=0.1)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50 # 一組50（一次訓練訓練個 TRAIN DATA / 50次）\n",
    "num_epochs = 50 # 訓練50次\n",
    "learning_rate = 0.01\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Epoch 6\n",
      "Epoch 11\n",
      "Epoch 16\n",
      "Epoch 21\n",
      "Epoch 26\n",
      "Epoch 31\n",
      "Epoch 36\n",
      "Epoch 41\n",
      "Epoch 46\n",
      "Epoch 1\n",
      "Epoch 6\n",
      "Epoch 11\n",
      "Epoch 16\n",
      "Epoch 21\n",
      "Epoch 26\n",
      "Epoch 31\n",
      "Epoch 36\n",
      "Epoch 41\n",
      "Epoch 46\n",
      "Epoch 1\n",
      "Epoch 6\n",
      "Epoch 11\n",
      "Epoch 16\n",
      "Epoch 21\n",
      "Epoch 26\n",
      "Epoch 31\n",
      "Epoch 36\n",
      "Epoch 41\n",
      "Epoch 46\n",
      "Epoch 1\n",
      "Epoch 6\n",
      "Epoch 11\n",
      "Epoch 16\n",
      "Epoch 21\n",
      "Epoch 26\n",
      "Epoch 31\n",
      "Epoch 36\n",
      "Epoch 41\n",
      "Epoch 46\n",
      "Epoch 1\n",
      "Epoch 6\n",
      "Epoch 11\n",
      "Epoch 16\n",
      "Epoch 21\n",
      "Epoch 26\n",
      "Epoch 31\n",
      "Epoch 36\n",
      "Epoch 41\n",
      "Epoch 46\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "train_acc_list = []                                   # 儲存每次訓練模型的準確度\n",
    "valid_acc_list = []                                   # 儲存每次驗證模型的準確度\n",
    "\n",
    "# 切train val\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "kf.get_n_splits(X_train)#因為x y數量一樣，所以把一個拿進去切就好\n",
    "\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "\n",
    "    x_train, x_test = X_train[train_index], X_train[test_index]\n",
    "    y_train, y_test = Y_train[train_index], Y_train[test_index]\n",
    "    batch_no = len(x_train) // batch_size\n",
    "    for epoch in range(num_epochs):\n",
    "        if epoch % 5 == 0:\n",
    "            print('Epoch {}'.format(epoch+1))\n",
    "\n",
    "        # 每個 batch learning\n",
    "        for i in range(batch_no):\n",
    "            #print('batch no:', i)\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "            \n",
    "            net.train()# 進入非訓練模式\n",
    "            \n",
    "            #丟給model必須是Variable  才能backward\n",
    "            x_var = torch.FloatTensor(x_train[start:end])#float\n",
    "            y_var = torch.LongTensor(y_train[start:end])#int\n",
    "\n",
    "            # Forward + Backward + Optimize\n",
    "            optimizer.zero_grad()\n",
    "            ypred_var = net(x_var) \n",
    "            loss =criterion(ypred_var, y_var)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            net.eval() # 進入非訓練模式\n",
    "            with torch.no_grad():\n",
    "                \n",
    "                x_train = torch.FloatTensor(x_train)#float\n",
    "                train_pred_y = net(x_train)\n",
    "                values, labels = torch.max(train_pred_y, 1)\n",
    "                train_acc = accuracy_score(y_train,         # 計算訓練資料準確度\n",
    "                                   labels)\n",
    "\n",
    "                x_test = torch.FloatTensor(x_test)\n",
    "                valid_pred_y = net(x_test)\n",
    "                values, labels = torch.max(valid_pred_y, 1)\n",
    "                valid_acc = accuracy_score(y_test,         # 計算驗證資料準確度\n",
    "                                   labels)\n",
    "\n",
    "                train_acc_list.append(train_acc)\n",
    "                valid_acc_list.append(valid_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train accuracy: 0.5190058639329465\n",
      "min train accuracy: 0.4734806629834254\n",
      "max train accuracy: 0.5582551076753175\n",
      "\n",
      "average valid accuracy: 0.5190593432616817\n",
      "min valid accuracy: 0.4370860927152318\n",
      "max valid accuracy: 0.5938189845474614\n"
     ]
    }
   ],
   "source": [
    "print((\n",
    "    'average train accuracy: {}\\n' +\n",
    "    'min train accuracy: {}\\n' +\n",
    "    'max train accuracy: {}').format(\n",
    "    np.mean(train_acc_list),                          # 輸出平均訓練準確度\n",
    "    np.min(train_acc_list),                           # 輸出最低訓練準確度\n",
    "    np.max(train_acc_list)                            # 輸出最高訓練準確度\n",
    "))\n",
    "print()\n",
    "print((\n",
    "    'average valid accuracy: {}\\n' +\n",
    "    'min valid accuracy: {}\\n' +\n",
    "    'max valid accuracy: {}').format(\n",
    "    np.mean(valid_acc_list),                          # 輸出平均驗證準確度\n",
    "    np.min(valid_acc_list),                           # 輸出最低驗證準確度\n",
    "    np.max(valid_acc_list)                            # 輸出最高驗證準確度\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.53761062\n"
     ]
    }
   ],
   "source": [
    "test_var = Variable(torch.FloatTensor(x_test), requires_grad=True)\n",
    "#test_y = Variable(torch.LongTensor(y_val), requires_grad=True)\n",
    "with torch.no_grad(): #深度學習模型在訓練時會自動計算梯度，若於分析模型在目標函數的表現時不想花多餘資源計算梯度可以使用 with to.no_grad():\n",
    "    result = net(test_var)\n",
    "\n",
    "values, labels = torch.max(result, 1) # 0以行取max / 0以列取max\n",
    "\n",
    "#MAX會回傳誰比較大 跟該index\n",
    "num_right = np.sum(labels.data.numpy() == y_test)\n",
    "#ACC = 猜中幾個\n",
    "print('Accuracy {:.8f}'.format(num_right / len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比rr直接訓練有好一點（47-> 53.761062）\n",
    "\n",
    "### 比較三個模型\n",
    "* RL: 0.47808765\n",
    "* SVM: 0.53761062\n",
    "* RR: 0.53761062\n",
    "\n",
    "其中以做過crossvalidation的RR最好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 試試看別的dataset\n",
    "以hw2的鐵達尼號資料舉例\n",
    "\n",
    "## RR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[參考這個網站](https://www.kaggle.com/kiranscaria/titanic-pytorch)\n",
    "###  資料前處理（不重要）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./train_t.csv') #用來當training資料的\n",
    "X_test = pd.read_csv('./test_t.csv')\n",
    "\n",
    "dataset_title = [i.split(',')[1].split('.')[0].strip() for i in dataset['Name']]\n",
    "dataset['Title'] = pd.Series(dataset_title)\n",
    "dataset.tail(5)\n",
    "dataset['Title'].value_counts()\n",
    "dataset['Title'] = dataset['Title'].replace(['Lady', 'the Countess', 'Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona', 'Ms', 'Mme', 'Mlle'], 'Rare')\n",
    "\n",
    "dataset_title = [i.split(',')[1].split('.')[0].strip() for i in X_test['Name']]\n",
    "X_test['Title'] = pd.Series(dataset_title)\n",
    "X_test['Title'].value_counts()\n",
    "X_test['Title'] = X_test['Title'].replace(['Lady', 'the Countess', 'Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona', 'Ms', 'Mme', 'Mlle'], 'Rare')\n",
    "\n",
    "dataset['FamilyS'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "X_test['FamilyS'] = X_test['SibSp'] + X_test['Parch'] + 1\n",
    "\n",
    "def family(x):\n",
    "    if x < 2:\n",
    "        return 'Single'\n",
    "    elif x == 2:\n",
    "        return 'Couple'\n",
    "    elif x <= 4:\n",
    "        return 'InterM'\n",
    "    else:\n",
    "        return 'Large'\n",
    "    \n",
    "dataset['FamilyS'] = dataset['FamilyS'].apply(family)\n",
    "X_test['FamilyS'] = X_test['FamilyS'].apply(family)\n",
    "dataset['Embarked'].fillna(dataset['Embarked'].mode()[0], inplace=True)\n",
    "X_test['Embarked'].fillna(X_test['Embarked'].mode()[0], inplace=True)\n",
    "dataset['Age'].fillna(dataset['Age'].median(), inplace=True)\n",
    "X_test['Age'].fillna(X_test['Age'].median(), inplace=True)\n",
    "X_test['Fare'].fillna(X_test['Fare'].median(), inplace=True)\n",
    "\n",
    "#dataset捨棄不用的欄位\n",
    "dataset = dataset.drop(['PassengerId', 'Cabin', 'Name', 'SibSp', 'Parch', 'Ticket'], axis=1)\n",
    "X_test_passengers = X_test['PassengerId']\n",
    "X_test = X_test.drop(['PassengerId', 'Cabin', 'Name', 'SibSp', 'Parch', 'Ticket'], axis=1)\n",
    "\n",
    "X_train = dataset.iloc[:, 1:8] #x捨棄Survived , .value的話會捨棄掉pclass那些\n",
    "\n",
    "Y_train = dataset.iloc[:, 0].values #y是survived\n",
    "\n",
    "# 註：test只保留特徵值，捨棄特徵名字"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 如果特徵中有string，將它轉換成數字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting categorical values to one-hot representation 用pandes\n",
    "\n",
    "X_train = pd.get_dummies(data=X_train, columns=['Sex', 'Embarked', 'Title', 'FamilyS'])\n",
    "X_test = pd.get_dummies(data=X_test, columns=['Sex', 'Embarked', 'Title', 'FamilyS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 所有運用到的資料全部變成value\n",
    "\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 開始訓練！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Epoch 6\n",
      "Epoch 11\n",
      "Epoch 16\n",
      "Epoch 21\n",
      "Epoch 26\n",
      "Epoch 31\n",
      "Epoch 36\n",
      "Epoch 41\n",
      "Epoch 46\n",
      "Epoch 1\n",
      "Epoch 6\n",
      "Epoch 11\n",
      "Epoch 16\n",
      "Epoch 21\n",
      "Epoch 26\n",
      "Epoch 31\n",
      "Epoch 36\n",
      "Epoch 41\n",
      "Epoch 46\n",
      "Epoch 1\n",
      "Epoch 6\n",
      "Epoch 11\n",
      "Epoch 16\n",
      "Epoch 21\n",
      "Epoch 26\n",
      "Epoch 31\n",
      "Epoch 36\n",
      "Epoch 41\n",
      "Epoch 46\n",
      "Epoch 1\n",
      "Epoch 6\n",
      "Epoch 11\n",
      "Epoch 16\n",
      "Epoch 21\n",
      "Epoch 26\n",
      "Epoch 31\n",
      "Epoch 36\n",
      "Epoch 41\n",
      "Epoch 46\n",
      "Epoch 1\n",
      "Epoch 6\n",
      "Epoch 11\n",
      "Epoch 16\n",
      "Epoch 21\n",
      "Epoch 26\n",
      "Epoch 31\n",
      "Epoch 36\n",
      "Epoch 41\n",
      "Epoch 46\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(17, 200) #270自己設定的嘛0.0\n",
    "        self.fc2 = nn.Linear(200, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.dropout(x, p=0.1)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "net = Net()\n",
    "\n",
    "batch_size = 50 # 一組50（一次訓練訓練個 TRAIN DATA / 50次）\n",
    "num_epochs = 50 # 訓練50次\n",
    "learning_rate = 0.01\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "train_acc_list = []                                   # 儲存每次訓練模型的準確度\n",
    "valid_acc_list = []                                   # 儲存每次驗證模型的準確度\n",
    "\n",
    "# 切train val\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "kf.get_n_splits(X_train)#因為x y數量一樣，所以把一個拿進去切就好\n",
    "\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    x_train, x_test = X_train[train_index], X_train[test_index]\n",
    "    y_train, y_test = Y_train[train_index], Y_train[test_index]\n",
    "    batch_no = len(x_train) // batch_size\n",
    "    for epoch in range(num_epochs):\n",
    "        if epoch % 5 == 0:\n",
    "            print('Epoch {}'.format(epoch+1))\n",
    "\n",
    "        # 每個 batch learning\n",
    "        for i in range(batch_no):\n",
    "            #print('batch no:', i)\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "            \n",
    "            net.train()# 進入非訓練模式\n",
    "            \n",
    "            #丟給model必須是Variable  才能backward\n",
    "            x_var = torch.FloatTensor(x_train[start:end])#float\n",
    "            y_var = torch.LongTensor(y_train[start:end])#int\n",
    "\n",
    "            # Forward + Backward + Optimize\n",
    "            optimizer.zero_grad()\n",
    "            ypred_var = net(x_var) \n",
    "            loss =criterion(ypred_var, y_var)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            net.eval() # 進入非訓練模式\n",
    "            with torch.no_grad():\n",
    "                \n",
    "                x_train = torch.FloatTensor(x_train)#float\n",
    "                train_pred_y = net(x_train)\n",
    "                values, labels = torch.max(train_pred_y, 1)\n",
    "                train_acc = accuracy_score(y_train,         # 計算訓練資料準確度\n",
    "                                   labels)\n",
    "\n",
    "                x_test = torch.FloatTensor(x_test)\n",
    "                valid_pred_y = net(x_test)\n",
    "                values, labels = torch.max(valid_pred_y, 1)\n",
    "                valid_acc = accuracy_score(y_test,         # 計算驗證資料準確度\n",
    "                                   labels)\n",
    "\n",
    "                train_acc_list.append(train_acc)\n",
    "                valid_acc_list.append(valid_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train accuracy: 0.8387749809207135\n",
      "min train accuracy: 0.6179775280898876\n",
      "max train accuracy: 0.8681626928471248\n",
      "\n",
      "average valid accuracy: 0.8182128733735664\n",
      "min valid accuracy: 0.6033519553072626\n",
      "max valid accuracy: 0.888268156424581\n"
     ]
    }
   ],
   "source": [
    "print((\n",
    "    'average train accuracy: {}\\n' +\n",
    "    'min train accuracy: {}\\n' +\n",
    "    'max train accuracy: {}').format(\n",
    "    np.mean(train_acc_list),                          # 輸出平均訓練準確度\n",
    "    np.min(train_acc_list),                           # 輸出最低訓練準確度\n",
    "    np.max(train_acc_list)                            # 輸出最高訓練準確度\n",
    "))\n",
    "print()\n",
    "print((\n",
    "    'average valid accuracy: {}\\n' +\n",
    "    'min valid accuracy: {}\\n' +\n",
    "    'max valid accuracy: {}').format(\n",
    "    np.mean(valid_acc_list),                          # 輸出平均驗證準確度\n",
    "    np.min(valid_acc_list),                           # 輸出最低驗證準確度\n",
    "    np.max(valid_acc_list)                            # 輸出最高驗證準確度\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 討論：為什麼RR 最好\n",
    "其實這樣的資料太難預測，什麼模型都無法有突破性的展現。\n",
    "rr比較好我猜想是因為我加入了crossvalidation的關係。\n",
    "所以股票投資有風險，小心為妙！"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
